{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.1.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os, time, itertools, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x):\n",
    "    # initializers\n",
    "    w_init = tf.truncated_normal_initializer(mean=0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.)\n",
    "\n",
    "    # 1st hidden layer\n",
    "    w0 = tf.get_variable('G_w0', [x.get_shape()[1], 256], initializer=w_init)\n",
    "    b0 = tf.get_variable('G_b0', [256], initializer=b_init)\n",
    "    h0 = tf.nn.relu(tf.matmul(x, w0) + b0)\n",
    "\n",
    "    # 2nd hidden layer\n",
    "    w1 = tf.get_variable('G_w1', [h0.get_shape()[1], 512], initializer=w_init)\n",
    "    b1 = tf.get_variable('G_b1', [512], initializer=b_init)\n",
    "    h1 = tf.nn.relu(tf.matmul(h0, w1) + b1)\n",
    "\n",
    "    # 3rd hidden layer\n",
    "    w2 = tf.get_variable('G_w2', [h1.get_shape()[1], 1024], initializer=w_init)\n",
    "    b2 = tf.get_variable('G_b2', [1024], initializer=b_init)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "\n",
    "    # output hidden layer\n",
    "    w3 = tf.get_variable('G_w3', [h2.get_shape()[1], 784], initializer=w_init)\n",
    "    b3 = tf.get_variable('G_b3', [784], initializer=b_init)\n",
    "    o = tf.nn.tanh(tf.matmul(h2, w3) + b3)\n",
    "\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D(x)\n",
    "# D(x)\n",
    "def discriminator(x):\n",
    "\n",
    "    # initializers\n",
    "    w_init = tf.truncated_normal_initializer(mean=0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.)\n",
    "\n",
    "    # 1st hidden layer\n",
    "    w0 = tf.get_variable('D_w0', [x.get_shape()[1], 1024], initializer=w_init)\n",
    "    b0 = tf.get_variable('D_b0', [1024], initializer=b_init)\n",
    "    h0 = tf.nn.relu(tf.matmul(x, w0) + b0)\n",
    "   # h0 = tf.nn.dropout(h0, drop_out)\n",
    "\n",
    "    # 2nd hidden layer\n",
    "    w1 = tf.get_variable('D_w1', [h0.get_shape()[1], 512], initializer=w_init)\n",
    "    b1 = tf.get_variable('D_b1', [512], initializer=b_init)\n",
    "    h1 = tf.nn.relu(tf.matmul(h0, w1) + b1)\n",
    "   # h1 = tf.nn.dropout(h1, drop_out)\n",
    "\n",
    "    # 3rd hidden layer\n",
    "    w2 = tf.get_variable('D_w2', [h1.get_shape()[1], 256], initializer=w_init)\n",
    "    b2 = tf.get_variable('D_b2', [256], initializer=b_init)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    #h2 = tf.nn.dropout(h2, drop_out)\n",
    "\n",
    "    # output layer\n",
    "    w3 = tf.get_variable('D_w3', [h2.get_shape()[1], 1], initializer=w_init)\n",
    "    b3 = tf.get_variable('D_b3', [1], initializer=b_init)\n",
    "    o = tf.sigmoid(tf.matmul(h2, w3) + b3)\n",
    "\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(num_epoch, show = False, save = False, path = 'result.png', isFix=False):\n",
    "    z_ = np.random.normal(0, 1, (25, 100))\n",
    "\n",
    "    if isFix:\n",
    "        test_images = sess.run(G_z, {z: fixed_z_})\n",
    "    else:\n",
    "        test_images = sess.run(G_z, {z: z_})\n",
    "\n",
    "    size_figure_grid = 5\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i, j].get_xaxis().set_visible(False)\n",
    "        ax[i, j].get_yaxis().set_visible(False)\n",
    "\n",
    "    for k in range(5*5):\n",
    "        i = k // 5\n",
    "        j = k % 5\n",
    "        ax[i, j].cla()\n",
    "        ax[i, j].imshow(np.reshape(test_images[k], (28, 28)), cmap='gray')\n",
    "\n",
    "    label = 'Epoch {0}'.format(num_epoch)\n",
    "    fig.text(0.5, 0.04, label, ha='center')\n",
    "    plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-ef10cb61c958>:7: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_core\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 100\n",
    "lr = 0.0002\n",
    "train_epoch = 100\n",
    "\n",
    "# load MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "train_set = (mnist.train.images - 0.5) / 0.5  # normalization; range: -1 ~ 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "# networks : generator\n",
    "with tf.variable_scope('G'):\n",
    "    z = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "    G_z = generator(z)\n",
    "# networks : discriminator\n",
    "with tf.variable_scope('D') as scope:\n",
    "  #  drop_out = tf.placeholder(dtype=tf.float32, name='drop_out')\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "    D_real = discriminator(x)\n",
    "    scope.reuse_variables()\n",
    "    D_fake = discriminator(G_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for each network\n",
    "eps = 1e-2\n",
    "D_loss = tf.reduce_mean(-tf.log(D_real + eps) - tf.log(1 - D_fake + eps))\n",
    "G_loss = tf.reduce_mean(-tf.log(D_fake + eps))\n",
    "\n",
    "# trainable variables for each network\n",
    "t_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in t_vars if 'D_' in var.name]\n",
    "G_vars = [var for var in t_vars if 'G_' in var.name]\n",
    "\n",
    "# optimizer for each network\n",
    "D_optim = tf.train.AdamOptimizer(lr).minimize(D_loss, var_list=D_vars)\n",
    "G_optim = tf.train.AdamOptimizer(lr).minimize(G_loss, var_list=G_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open session and initialize all variables\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results save folder\n",
    "if not os.path.isdir('MNIST_GAN_results'):\n",
    "    os.mkdir('MNIST_GAN_results')\n",
    "if not os.path.isdir('MNIST_GAN_results/results'):\n",
    "    os.mkdir('MNIST_GAN_results/results')\n",
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "train_hist['per_epoch_ptimes'] = []\n",
    "train_hist['total_ptime'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_z_ = np.random.normal(0, 1, (25, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] - ptime: 35.76 loss_d: 1.196, loss_g: 2.169\n",
      "[2/100] - ptime: 41.18 loss_d: 4.596, loss_g: -0.010\n",
      "[3/100] - ptime: 39.49 loss_d: 3.834, loss_g: 0.561\n",
      "[4/100] - ptime: 37.54 loss_d: 1.010, loss_g: 1.597\n",
      "[5/100] - ptime: 37.03 loss_d: 1.042, loss_g: 3.373\n",
      "[6/100] - ptime: 36.67 loss_d: 0.598, loss_g: 3.054\n",
      "[7/100] - ptime: 46.89 loss_d: 0.510, loss_g: 3.049\n",
      "[8/100] - ptime: 39.75 loss_d: 0.547, loss_g: 3.146\n",
      "[9/100] - ptime: 47.71 loss_d: 0.478, loss_g: 3.169\n",
      "[10/100] - ptime: 42.71 loss_d: 0.510, loss_g: 3.153\n",
      "[11/100] - ptime: 43.24 loss_d: 0.407, loss_g: 3.550\n",
      "[12/100] - ptime: 44.87 loss_d: 0.406, loss_g: 3.579\n",
      "[13/100] - ptime: 47.97 loss_d: 0.476, loss_g: 3.656\n",
      "[14/100] - ptime: 48.90 loss_d: 0.615, loss_g: 2.839\n",
      "[15/100] - ptime: 47.79 loss_d: 0.614, loss_g: 2.601\n",
      "[16/100] - ptime: 48.39 loss_d: 0.568, loss_g: 3.082\n",
      "[17/100] - ptime: 44.03 loss_d: 0.608, loss_g: 2.535\n",
      "[18/100] - ptime: 47.23 loss_d: 0.458, loss_g: 2.916\n",
      "[19/100] - ptime: 42.93 loss_d: 0.526, loss_g: 2.867\n",
      "[20/100] - ptime: 44.56 loss_d: 0.422, loss_g: 3.352\n",
      "[21/100] - ptime: 72.02 loss_d: 0.406, loss_g: 3.305\n",
      "[22/100] - ptime: 44.36 loss_d: 0.441, loss_g: 3.115\n",
      "[23/100] - ptime: 42.27 loss_d: 0.460, loss_g: 3.205\n",
      "[24/100] - ptime: 45.56 loss_d: 0.440, loss_g: 2.929\n",
      "[25/100] - ptime: 43.49 loss_d: 0.482, loss_g: 3.011\n",
      "[26/100] - ptime: 47.31 loss_d: 0.462, loss_g: 3.039\n",
      "[27/100] - ptime: 40.83 loss_d: 0.497, loss_g: 2.729\n",
      "[28/100] - ptime: 38.73 loss_d: 0.474, loss_g: 2.690\n",
      "[29/100] - ptime: 42.22 loss_d: 0.452, loss_g: 2.863\n",
      "[30/100] - ptime: 40.98 loss_d: 0.485, loss_g: 2.779\n",
      "[31/100] - ptime: 39.24 loss_d: 0.531, loss_g: 2.621\n",
      "[32/100] - ptime: 42.29 loss_d: 0.554, loss_g: 2.598\n",
      "[33/100] - ptime: 49.34 loss_d: 0.577, loss_g: 2.415\n",
      "[34/100] - ptime: 41.26 loss_d: 0.511, loss_g: 2.581\n",
      "[35/100] - ptime: 45.65 loss_d: 0.549, loss_g: 2.457\n",
      "[36/100] - ptime: 42.76 loss_d: 0.564, loss_g: 2.300\n",
      "[37/100] - ptime: 41.29 loss_d: 0.579, loss_g: 2.217\n",
      "[38/100] - ptime: 41.52 loss_d: 0.582, loss_g: 2.306\n",
      "[39/100] - ptime: 44.48 loss_d: 0.624, loss_g: 2.131\n",
      "[40/100] - ptime: 37.65 loss_d: 0.683, loss_g: 1.992\n",
      "[41/100] - ptime: 40.66 loss_d: 0.650, loss_g: 2.053\n",
      "[42/100] - ptime: 38.42 loss_d: 0.675, loss_g: 1.987\n",
      "[43/100] - ptime: 43.83 loss_d: 0.678, loss_g: 1.959\n",
      "[44/100] - ptime: 43.78 loss_d: 0.680, loss_g: 1.988\n",
      "[45/100] - ptime: 44.48 loss_d: 0.699, loss_g: 1.920\n",
      "[46/100] - ptime: 37.51 loss_d: 0.705, loss_g: 1.857\n",
      "[47/100] - ptime: 37.32 loss_d: 0.704, loss_g: 1.892\n",
      "[48/100] - ptime: 36.46 loss_d: 0.725, loss_g: 1.810\n",
      "[49/100] - ptime: 37.09 loss_d: 0.734, loss_g: 1.830\n",
      "[50/100] - ptime: 37.56 loss_d: 0.734, loss_g: 1.822\n",
      "[51/100] - ptime: 40.16 loss_d: 0.750, loss_g: 1.754\n",
      "[52/100] - ptime: 38.01 loss_d: 0.763, loss_g: 1.704\n",
      "[53/100] - ptime: 40.99 loss_d: 0.748, loss_g: 1.755\n",
      "[54/100] - ptime: 48.92 loss_d: 0.762, loss_g: 1.739\n",
      "[55/100] - ptime: 37.45 loss_d: 0.771, loss_g: 1.703\n",
      "[56/100] - ptime: 40.28 loss_d: 0.798, loss_g: 1.624\n",
      "[57/100] - ptime: 39.11 loss_d: 0.796, loss_g: 1.655\n",
      "[58/100] - ptime: 38.45 loss_d: 0.806, loss_g: 1.609\n",
      "[59/100] - ptime: 41.48 loss_d: 0.803, loss_g: 1.609\n",
      "[60/100] - ptime: 38.84 loss_d: 0.814, loss_g: 1.600\n",
      "[61/100] - ptime: 48.06 loss_d: 0.816, loss_g: 1.586\n",
      "[62/100] - ptime: 43.79 loss_d: 0.817, loss_g: 1.555\n",
      "[63/100] - ptime: 42.46 loss_d: 0.820, loss_g: 1.554\n",
      "[64/100] - ptime: 39.19 loss_d: 0.826, loss_g: 1.548\n",
      "[65/100] - ptime: 44.76 loss_d: 0.825, loss_g: 1.567\n",
      "[66/100] - ptime: 41.28 loss_d: 0.841, loss_g: 1.540\n",
      "[67/100] - ptime: 42.23 loss_d: 0.846, loss_g: 1.492\n",
      "[68/100] - ptime: 40.87 loss_d: 0.832, loss_g: 1.537\n",
      "[69/100] - ptime: 39.87 loss_d: 0.847, loss_g: 1.514\n",
      "[70/100] - ptime: 40.18 loss_d: 0.849, loss_g: 1.516\n",
      "[71/100] - ptime: 41.10 loss_d: 0.851, loss_g: 1.511\n",
      "[72/100] - ptime: 39.64 loss_d: 0.860, loss_g: 1.519\n",
      "[73/100] - ptime: 39.23 loss_d: 0.858, loss_g: 1.488\n",
      "[74/100] - ptime: 41.64 loss_d: 0.867, loss_g: 1.470\n",
      "[75/100] - ptime: 39.75 loss_d: 0.865, loss_g: 1.477\n",
      "[76/100] - ptime: 40.56 loss_d: 0.862, loss_g: 1.463\n",
      "[77/100] - ptime: 44.43 loss_d: 0.867, loss_g: 1.469\n",
      "[78/100] - ptime: 38.80 loss_d: 0.864, loss_g: 1.497\n",
      "[79/100] - ptime: 50.93 loss_d: 0.871, loss_g: 1.460\n",
      "[80/100] - ptime: 44.69 loss_d: 0.876, loss_g: 1.455\n",
      "[81/100] - ptime: 39.41 loss_d: 0.879, loss_g: 1.454\n",
      "[82/100] - ptime: 38.40 loss_d: 0.866, loss_g: 1.447\n",
      "[83/100] - ptime: 41.98 loss_d: 0.876, loss_g: 1.445\n",
      "[84/100] - ptime: 39.19 loss_d: 0.875, loss_g: 1.456\n",
      "[85/100] - ptime: 43.12 loss_d: 0.877, loss_g: 1.443\n",
      "[86/100] - ptime: 39.46 loss_d: 0.871, loss_g: 1.456\n",
      "[87/100] - ptime: 39.03 loss_d: 0.875, loss_g: 1.455\n",
      "[88/100] - ptime: 41.16 loss_d: 0.867, loss_g: 1.477\n",
      "[89/100] - ptime: 43.48 loss_d: 0.875, loss_g: 1.449\n",
      "[90/100] - ptime: 39.01 loss_d: 0.869, loss_g: 1.476\n",
      "[91/100] - ptime: 41.14 loss_d: 0.864, loss_g: 1.457\n",
      "[92/100] - ptime: 42.17 loss_d: 0.867, loss_g: 1.477\n",
      "[93/100] - ptime: 42.15 loss_d: 0.860, loss_g: 1.486\n",
      "[94/100] - ptime: 43.15 loss_d: 0.865, loss_g: 1.477\n",
      "[95/100] - ptime: 37.90 loss_d: 0.859, loss_g: 1.464\n",
      "[96/100] - ptime: 38.38 loss_d: 0.859, loss_g: 1.474\n",
      "[97/100] - ptime: 45.02 loss_d: 0.854, loss_g: 1.477\n",
      "[98/100] - ptime: 39.53 loss_d: 0.847, loss_g: 1.498\n",
      "[99/100] - ptime: 40.08 loss_d: 0.842, loss_g: 1.510\n",
      "[100/100] - ptime: 52.90 loss_d: 0.853, loss_g: 1.481\n",
      "Avg per epoch ptime: 42.19, total 100 epochs ptime: 4492.63\n",
      "Training finish!... save training results\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'imageio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e267fb8ac6af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mimg_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MNIST_GAN_results/Fixed_results/MNIST_GAN_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MNIST_GAN_results/generation_animation.gif'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imageio' is not defined"
     ]
    }
   ],
   "source": [
    "# training-loop\n",
    "np.random.seed(int(time.time()))\n",
    "start_time = time.time()\n",
    "for epoch in range(train_epoch):\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    for iter in range(train_set.shape[0] // batch_size):\n",
    "        # update discriminator\n",
    "        x_ = train_set[iter*batch_size:(iter+1)*batch_size]\n",
    "        z_ = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        loss_d_, _ = sess.run([D_loss, D_optim], {x: x_, z: z_})\n",
    "        D_losses.append(loss_d_)\n",
    "\n",
    "        # update generator\n",
    "        z_ = np.random.normal(0, 1, (batch_size, 100))\n",
    "        loss_g_, _ = sess.run([G_loss, G_optim], {z: z_})\n",
    "        G_losses.append(loss_g_)\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "    print('[%d/%d] - ptime: %.2f loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime, np.mean(D_losses), np.mean(G_losses)))\n",
    "    p = 'MNIST_GAN_results/Random_results/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "    fixed_p = 'MNIST_GAN_results/Fixed_results/MNIST_GAN_' + str(epoch + 1) + '.png'\n",
    "    show_result((epoch + 1), save=True, path=p, isFix=False)\n",
    "    show_result((epoch + 1), save=True, path=fixed_p, isFix=True)\n",
    "    train_hist['D_losses'].append(np.mean(D_losses))\n",
    "    train_hist['G_losses'].append(np.mean(G_losses))\n",
    "    train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "\n",
    "end_time = time.time()\n",
    "total_ptime = end_time - start_time\n",
    "train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(train_hist['per_epoch_ptimes']), train_epoch, total_ptime))\n",
    "print(\"Training finish!... save training results\")\n",
    "with open('MNIST_GAN_results/train_hist.pkl', 'wb') as f:\n",
    "    pickle.dump(train_hist, f)\n",
    "show_train_hist(train_hist, save=True, path='MNIST_GAN_results/MNIST_GAN_train_hist.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
      "Collecting pillow (from imageio)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/9c/04297251a6e38b8506a4fcee17a1f16765a12ab8d805f9fd9e0fda424fec/Pillow-7.1.1-cp37-cp37m-win_amd64.whl (2.0MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from imageio) (1.18.2)\n",
      "Installing collected packages: pillow, imageio\n",
      "Successfully installed imageio-2.8.0 pillow-7.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts imageio_download_bin.exe and imageio_remove_bin.exe are installed in 'C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "images = []\n",
    "for e in range(train_epoch):\n",
    "    img_name = 'MNIST_GAN_results/Fixed_results/MNIST_GAN_' + str(e + 1) + '.png'\n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave('MNIST_GAN_results/generation_animation.gif', images, fps=5)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
